{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "directory = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\Data Invoice 20230327\\\\NAM 2023\\\\Month 2'\n",
    "directory2 = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\Data Invoice 20230327\\\\NAM 2023\\\\Month 2'\n",
    "cate_dir = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\DataCate.xlsx'\n",
    "cate_dir2 = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\DataCate.xlsx'\n",
    "\n",
    "# list of Excel files to read data from\n",
    "if os.path.exists(os.path.join(directory, '230201 Payment Summary - 2023-01-31T145747.301.xlsx')):\n",
    "    excel_files = glob.glob(os.path.join(directory, '*.xlsx'))\n",
    "else:\n",
    "    excel_files = glob.glob(os.path.join(directory2, '*.xlsx'))\n",
    "try:\n",
    "    # use cols 0, Barcode; 2, Category Name\n",
    "    # df2 = pd.read_excel(cate_dir, sheet_name='Sheet1', usecols=[0,2])\n",
    "    # use cols 0, Barcode; 3, SubCategory Name\n",
    "    df2 = pd.read_excel(cate_dir, sheet_name='Sheet1', usecols=[0,3])\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    # df2 = pd.read_excel(cate_dir2, sheet_name='Sheet1', usecols=[0,2])\n",
    "    # use cols 0, Barcode; 3, SubCategory Name\n",
    "    df2 = pd.read_excel(cate_dir2, sheet_name='Sheet1', usecols=[0,3])\n",
    "    pass\n",
    "\n",
    "outputfile =  'dataM1.csv'\n",
    "# def excel2csv\n",
    "def excel2csv(inputfile, outputfile):\n",
    "    \n",
    "    # Check if exist file_path\n",
    "    if not os.path.exists(outputfile):\n",
    "        with open(outputfile, 'w') as f:\n",
    "            pass\n",
    "\n",
    "    # Read the first line of the file\n",
    "    with open(outputfile, 'r') as f:\n",
    "        first_line = f.readline().strip()\n",
    "    # Check if the first line contains the expected column names\n",
    "    has_headers = 'InvoiceID' in first_line\n",
    "    df = pd.read_excel(inputfile, sheet_name='Sheet2', skiprows=2, usecols=[4,7,8,14])\n",
    "    # df2 Category\n",
    "    \n",
    "    # merge with Category, on \"Barcode\"\n",
    "    df = df.merge(df2, on='Barcode', how='left')\n",
    "    \n",
    "    # Check if the first line contains the expected column names\n",
    "    df.to_csv(outputfile, mode='a', header= not has_headers, index=False)\n",
    "\n",
    "\n",
    "# loop through the list of Excel files\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    [executor.submit(excel2csv, file, outputfile) for file in excel_files]\n",
    "    # for file in excel_files:\n",
    "    #     executor.submit(excel2csv,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample data\n",
    "dtypes = {'InvoiceID': str, 'Barcode': str, 'Sum of Qty': str, 'Total Exclude VAT': str, 'SubCategory Name': str}\n",
    "df = pd.read_csv('C:\\\\Users\\\\Trieu Pham\\\\Desktop\\\\dataT1.csv', dtype=dtypes, error_bad_lines=False)\n",
    "\n",
    "df['Sum of Qty'] = pd.to_numeric(df['Sum of Qty'], errors='coerce').fillna(0).astype(int)\n",
    "df['Total Exclude VAT'] = pd.to_numeric(df['Total Exclude VAT'], errors='coerce').fillna(0).astype(float)\n",
    "df['SubCategory Name'] = df['SubCategory Name'].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bill0 = df1.groupby('InvoiceID').filter(lambda x: x['Sum of Qty'].sum() == 0)\n",
    "\n",
    "bill0 = df[df['Sum of Qty'] == 0]\n",
    "\n",
    "bill0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m      7\u001b[0m df_filtered \u001b[39m=\u001b[39m df[(df[\u001b[39m'\u001b[39m\u001b[39mSum of Qty\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mTotal Exclude VAT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)]\n\u001b[0;32m     10\u001b[0m \u001b[39m# Calculate the IQR and filter out outliers\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Q1 = np.percentile(df_filtered['Total Exclude VAT'], 5)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Q3 = np.percentile(df_filtered['Total Exclude VAT'], 95)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# lower_bound = 1000\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# df_filtered = df_filtered[df_filtered['Total Exclude VAT'] <= upper_bound]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m new_df \u001b[39m=\u001b[39m df_filtered\u001b[39m.\u001b[39;49mdropna()\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mInvoiceID\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49magg({\u001b[39m'\u001b[39;49m\u001b[39mBarcode\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mlambda\u001b[39;49;00m x: \u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)), \n\u001b[0;32m     19\u001b[0m                                       \u001b[39m'\u001b[39;49m\u001b[39mSum of Qty\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     20\u001b[0m                                       \u001b[39m'\u001b[39;49m\u001b[39mTotal Exclude VAT\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     21\u001b[0m                                       \u001b[39m'\u001b[39;49m\u001b[39mSubCategory Name\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mlambda\u001b[39;49;00m x: \u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m))})\n\u001b[0;32m     23\u001b[0m new_df\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:895\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    892\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m    894\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[1;32m--> 895\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    173\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    174\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:504\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    502\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[0;32m    505\u001b[0m         key: obj\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    506\u001b[0m     }\n\u001b[0;32m    508\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[0;32m    509\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:505\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    501\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    502\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m    504\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[1;32m--> 505\u001b[0m         key: obj\u001b[39m.\u001b[39;49m_gotitem(key, ndim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    506\u001b[0m     }\n\u001b[0;32m    508\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[0;32m    509\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:297\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# TODO: KeyError is raised in _python_agg_general,\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[39m#  see test_groupby.test_basic\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_named(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1682\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general\u001b[1;34m(self, func, raise_on_typeerror, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1678\u001b[0m name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mname\n\u001b[0;32m   1680\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[39m# if this function is invalid for this dtype, we will ignore it.\u001b[39;00m\n\u001b[1;32m-> 1682\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(obj, f)\n\u001b[0;32m   1683\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_typeerror:\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1081\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m   1078\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1081\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m   1083\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1104\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1101\u001b[0m splitter \u001b[39m=\u001b[39m get_splitter(obj, ids, ngroups, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1103\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1104\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[0;32m   1105\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[0;32m   1107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[0;32m   1108\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1668\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_agg_general\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, raise_on_typeerror\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1667\u001b[0m     func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mis_builtin_func(func)\n\u001b[1;32m-> 1668\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1670\u001b[0m     \u001b[39m# iterate through \"columns\" ex exclusions to populate output dict\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m     output: \u001b[39mdict\u001b[39m[base\u001b[39m.\u001b[39mOutputKey, ArrayLike] \u001b[39m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m df_filtered \u001b[39m=\u001b[39m df[(df[\u001b[39m'\u001b[39m\u001b[39mSum of Qty\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mTotal Exclude VAT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)]\n\u001b[0;32m     10\u001b[0m \u001b[39m# Calculate the IQR and filter out outliers\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Q1 = np.percentile(df_filtered['Total Exclude VAT'], 5)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Q3 = np.percentile(df_filtered['Total Exclude VAT'], 95)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# lower_bound = 1000\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# df_filtered = df_filtered[df_filtered['Total Exclude VAT'] <= upper_bound]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m new_df \u001b[39m=\u001b[39m df_filtered\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mInvoiceID\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mBarcode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(x\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)), \n\u001b[0;32m     19\u001b[0m                                       \u001b[39m'\u001b[39m\u001b[39mSum of Qty\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     20\u001b[0m                                       \u001b[39m'\u001b[39m\u001b[39mTotal Exclude VAT\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     21\u001b[0m                                       \u001b[39m'\u001b[39m\u001b[39mSubCategory Name\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(x\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m))})\n\u001b[0;32m     23\u001b[0m new_df\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Trieu Pham\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:114\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    111\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mensure_string_array(\n\u001b[0;32m    113\u001b[0m         arr, skipna\u001b[39m=\u001b[39;49mskipna, convert_na_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m--> 114\u001b[0m     )\u001b[39m.\u001b[39;49mreshape(shape)\n\u001b[0;32m    116\u001b[0m \u001b[39melif\u001b[39;00m is_datetime64_dtype(arr\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mint64:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter out rows where 'Sum of Qty' or 'Total Exclude VAT' are zero\n",
    "df_filtered = df[(df['Sum of Qty'] > 0) & (df['Total Exclude VAT'] > 0)]\n",
    "\n",
    "\n",
    "# Calculate the IQR and filter out outliers\n",
    "# Q1 = np.percentile(df_filtered['Total Exclude VAT'], 5)\n",
    "# Q3 = np.percentile(df_filtered['Total Exclude VAT'], 95)\n",
    "# IQR = Q3 - Q1\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "# lower_bound = 1000\n",
    "# df_filtered = df_filtered[df_filtered['Total Exclude VAT'] <= upper_bound]\n",
    "\n",
    "new_df = df_filtered.dropna().groupby('InvoiceID').agg({'Barcode': lambda x: ', '.join(x.astype(str)), \n",
    "                                      'Sum of Qty': 'sum', \n",
    "                                      'Total Exclude VAT': 'sum', \n",
    "                                      'SubCategory Name': lambda x: ', '.join(x.astype(str))})\n",
    "\n",
    "new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"dataCleanM2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the data based on Total Exclude VAT and calculate the counts\n",
    "bins = np.concatenate(([0], np.arange(10000, 100001, 5000), [np.inf]))\n",
    "labels = ['<10,000'] + ['{} to {}' .format(i, i+4999) for i in range(10000, 100000, 5000)] + ['>=100,000']\n",
    "df_filtered['VAT_group'] = pd.cut(df_filtered['Total Exclude VAT'], bins=bins, labels=labels)\n",
    "grouped_data = df_filtered.groupby('VAT_group')['Total Exclude VAT'].agg(['count','mean'])\n",
    "\n",
    "# Calculate the mean, mode, and median of 'Total Exclude VAT' column\n",
    "basket_values = new_df['Total Exclude VAT'].tolist()\n",
    "\n",
    "mean = statistics.mean(basket_values)\n",
    "mode = statistics.mode(basket_values)\n",
    "median = statistics.median(basket_values)\n",
    "std = statistics.stdev(basket_values)\n",
    "min = min(basket_values)\n",
    "max = max(basket_values)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Mode: \", mode)\n",
    "print(\"Median: \", median)\n",
    "print(\"Std \",std)\n",
    "print(\"Min: \",min)\n",
    "print(\"Max: \",max)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.      How many Quantity Items in Bill 2+\n",
    "\n",
    "qty_item_arr = bill2['Sum of Qty'].to_list()\n",
    "qty_item_arr = [int(x) for x in qty_item_arr if x != 'Sum of Qty']\n",
    "sum_qty = sum(qty_item_arr)\n",
    "\n",
    "sum_qty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.      How much Net Sales Exclude VAT in Bill 2+\n",
    "import csv\n",
    "\n",
    "qty_net_arr = bill2['Total Exclude VAT'].to_list()\n",
    "# bill2['Total Exclude VAT'].to_csv(\"NetSales.csv\",index=False)\n",
    "# qty_net_arr = [float(float(x)) for x in qty_net_arr if x != 'Total Exclude VAT']\n",
    "qty_net_arr = [(int(float(x))) for x in qty_net_arr if x != 'Total Exclude VAT']\n",
    "\n",
    "with open('NetSales1.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for x in qty_net_arr:\n",
    "        writer.writerow([x])\n",
    "\n",
    "sum_net = sum(qty_net_arr)\n",
    "\n",
    "len(qty_net_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number unique items: {len(unique_items)}\")\n",
    "print(f\"Summary quantity items: {sum_qty}\")\n",
    "print(f\"Summary net Sales Exclude VAT: {sum_net}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.     Calculations:\n",
    "# a.      What is the Percentage between Bill 1 and Bill 2+ in Total Net Sales, Total Bills, and Total Items => This only needs one result for each by month\n",
    "# b.      How much Average Net Sales on Bill 2+ => To know the Real Basket Value\n",
    "# c.      How many Average Unique Items in Bill 2+ => To know more insights the Basket\n",
    "# d.      How many Average Items in Bill 2+ => To know more insights into the Basket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Bill1\n",
    "bill1 = df1[df1.groupby('InvoiceID')['Sum of Qty'].transform('size') == 1]\n",
    "\n",
    "bill1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. What is the Percentage between Bill 1 and Bill 2+ in Total Net Sales, Total Bills, and Total Items \n",
    "\n",
    "## Get bill1 Total Net Sales\n",
    "qty_net_arr1 = bill1['Total Exclude VAT'].to_list()\n",
    "qty_net_arr1 = [int(float(x)) for x in qty_net_arr1 if x != 'Total Exclude VAT']\n",
    "sum_net1 = sum(qty_net_arr1)\n",
    "## Percentage between Bill 1 and Bill 2+ in Total Net Sales\n",
    "total_net_perc = sum_net1/sum_net\n",
    "\n",
    "total_net_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get bill1 Total Bills\n",
    "import numpy as np\n",
    "unique_bill1 = np.unique(bill1['InvoiceID'])\n",
    "unique_bill2 = np.unique(bill2['InvoiceID'])\n",
    "## Percentage between Bill 1 and Bill 2+ in Total Bills\n",
    "total_bills_perc = len(unique_bill1)/len(unique_bill2)\n",
    "\n",
    "total_bills_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantity items in bill1\n",
    "qty_item_arr1 = bill1['Sum of Qty'].to_list()\n",
    "qty_item_arr1 = [int(x) for x in qty_item_arr1 if x != 'Sum of Qty']\n",
    "sum_qty1 = sum(qty_item_arr1)\n",
    "## Percentage between Bill 1 and Bill 2+ in Total Items\n",
    "total_qty_perc = sum_qty1/sum_qty\n",
    "\n",
    "total_qty_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.      How much Average Net Sales on Bill 2+ => To know the Real Basket Value\n",
    "\n",
    "avg_net_sales = sum_net/len(unique_bill2)\n",
    "\n",
    "avg_net_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.      How many Average Unique Items in Bill 2+ => To know more insights the Basket\n",
    "avg_unique_items = len(unique_items)/len(bill2)\n",
    "\n",
    "avg_unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.      How many Average Items in Bill 2+ => To know more insights into the Basket\n",
    "\n",
    "avg_item_bills = sum_qty/len(bill2.drop_duplicates(subset='InvoiceID'))\n",
    "\n",
    "avg_item_bills"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f2380935a852bfd6cd376048d8438f0291ac020ced12a3def74eecbc5a3998c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
