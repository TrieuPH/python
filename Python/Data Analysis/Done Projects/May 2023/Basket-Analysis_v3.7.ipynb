{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import glob\n",
    "# import concurrent.futures\n",
    "# import time\n",
    "\n",
    "# directory = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\Data Invoice\\\\NAM 2023\\\\Month 3'\n",
    "# directory2 = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\Data Invoice\\\\NAM 2023\\\\Month 3'\n",
    "# cate_dir = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\DataCate.xlsx'\n",
    "# cate_dir2 = 'C:\\\\Users\\\\minhtriet.pham\\\\Desktop\\\\DataCate.xlsx'\n",
    "\n",
    "# # list of Excel files to read data from\n",
    "# if os.path.exists(os.path.join(directory, '230301 Payment Summary - 2023-03-02T084245.428.xlsx')):\n",
    "#     excel_files = glob.glob(os.path.join(directory, '*.xlsx'))\n",
    "# else:\n",
    "#     excel_files = glob.glob(os.path.join(directory2, '*.xlsx'))\n",
    "# try:\n",
    "#     # # use cols 0, Barcode; 2, Category Name\n",
    "#     # df2 = pd.read_excel(cate_dir, sheet_name='Sheet1', usecols=[0,2])\n",
    "#     # use cols 0, Barcode; 3, SubCategory Name\n",
    "#     df2 = pd.read_excel(cate_dir, sheet_name='Sheet1', usecols=[0,3])\n",
    "#     pass\n",
    "# except FileNotFoundError:\n",
    "#     # df2 = pd.read_excel(cate_dir2, sheet_name='Sheet1', usecols=[0,2])\n",
    "#     # use cols 0, Barcode; 3, SubCategory Name\n",
    "#     df2 = pd.read_excel(cate_dir2, sheet_name='Sheet1', usecols=[0,3])\n",
    "#     pass\n",
    "# # create an empty list to store the dataframes\n",
    "# # dfs = [] sho\n",
    "\n",
    "# outputfile =  'dataM1.csv'\n",
    "# # def excel2csv\n",
    "# def excel2csv(inputfile, outputfile):\n",
    "    \n",
    "#     # Check if exist file_path\n",
    "#     if not os.path.exists(outputfile):\n",
    "#         with open(outputfile, 'w') as f:\n",
    "#             pass\n",
    "\n",
    "#     # Read the first line of the file\n",
    "#     with open(outputfile, 'r') as f:\n",
    "#         first_line = f.readline().strip()\n",
    "#     # Check if the first line contains the expected column names\n",
    "#     has_headers = 'InvoiceID' in first_line\n",
    "#     df = pd.read_excel(inputfile, sheet_name='Sheet2', skiprows=2, usecols=[4,7,8,14])\n",
    "#     # df2 Category\n",
    "#     # # merge with Category, on \"Barcode\"\n",
    "#     # df = df.merge(df2, on='Barcode', how='left')\n",
    "#     # merge with Sub Category, on \"Barcode\"\n",
    "#     df = df.merge(df2, on='Barcode', how='left')\n",
    "    \n",
    "#     # Check if the first line contains the expected column names\n",
    "#     df.to_csv(outputfile, mode='a', header= not has_headers, index=False)\n",
    "\n",
    "\n",
    "# # loop through the list of Excel files\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     [executor.submit(excel2csv, file, outputfile) for file in excel_files]\n",
    "#     # for file in excel_files:\n",
    "#     #     executor.submit(excel2csv,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5377868 entries, 0 to 5377867\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   InvoiceID          object \n",
      " 1   Barcode            object \n",
      " 2   Sum of Qty         int64  \n",
      " 3   Total Exclude VAT  float64\n",
      " 4   SubCategory Name   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 205.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "dtypes = {'InvoiceID': str, 'Barcode': str, 'Sum of Qty': str, 'Total Exclude VAT': str, 'SubCategory Name': str}\n",
    "# df = pd.read_csv(r'C:\\Users\\minhtriet.pham\\Desktop\\New folder\\Quantity\\dataM1.csv', dtype=dtypes, on_bad_lines='warn')\n",
    "try:\n",
    "    df = pd.read_csv(r'C:\\Users\\trieu.pham\\OneDrive - BTM Global Consulting\\Projects\\data csv\\dataM1.csv', dtype=dtypes, on_bad_lines='warn')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv(r'/Users/trieupham/Library/CloudStorage/OneDrive-BTMGlobalConsulting/Projects/data csv/dataM1.csv', dtype=dtypes, on_bad_lines='warn')\n",
    "except:\n",
    "    df = pd.read_csv(r'C:\\Users\\minhtriet.pham\\Desktop\\New folder\\Quantity\\dataM1.csv', dtype=dtypes, on_bad_lines='warn')\n",
    "\n",
    "df['Sum of Qty'] = pd.to_numeric(df['Sum of Qty'], errors='coerce').fillna(0).astype(int)\n",
    "df['Total Exclude VAT'] = pd.to_numeric(df['Total Exclude VAT'], errors='coerce').fillna(0).astype(float)\n",
    "df['SubCategory Name'] = df['SubCategory Name'].astype(str)\n",
    "# df['Category Name'] = df['Category Name'].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter InvoiceIDs where sum of Qty is 0 for all barcodes\n",
    "invoice_ids_with_zero_qty = df.groupby('InvoiceID').filter(lambda x: x['Sum of Qty'].sum() == 0)['InvoiceID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the original data frame based on the InvoiceIDs\n",
    "df_filtered_invoice_id_zero_qty = df[df['InvoiceID'].isin(invoice_ids_with_zero_qty)]\n",
    "\n",
    "df_filtered_invoice_id_zero_qty.sort_values(by=['InvoiceID', 'Barcode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find records in df that are not included in df_filtered_invoice_id_zero_qty\n",
    "df_filtered = pd.merge(df, df_filtered_invoice_id_zero_qty, on=['InvoiceID', 'Barcode', 'Sum of Qty', 'Total Exclude VAT', 'SubCategory Name'], how='left', indicator=True)\n",
    "df_filtered = df_filtered[df_filtered['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# filter out rows where 'Sum of Qty' or 'Total Exclude VAT' are zero\n",
    "# df_filtered = df[(df['Sum of Qty'] > 0) & (df['Total Exclude VAT'] > 0)]\n",
    "\n",
    "group_by_invoice = df_filtered.dropna().groupby('InvoiceID').agg({'Barcode': lambda x: ', '.join(x.astype(str)), \n",
    "                                      'Sum of Qty': 'sum', \n",
    "                                      'Total Exclude VAT': 'sum', \n",
    "                                      'SubCategory Name': lambda x: ', '.join(x.astype(str))}).reset_index()\n",
    "group_by_invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# filter group_by_invoice by upper_bound and lower_bound\n",
    "upper_bound = 50000000\n",
    "lower_bound = 1000\n",
    "\n",
    "group_by_invoice_filtered = group_by_invoice[(group_by_invoice['Total Exclude VAT'] >= lower_bound) & (group_by_invoice['Total Exclude VAT'] <= upper_bound)]\n",
    "\n",
    "group_by_invoice_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from scipy import stats\n",
    "# Calculate the statistical measures using describe() method\n",
    "stat = group_by_invoice_filtered.describe()\n",
    "\n",
    "# Calculate the median and mode of the 'Total Exclude VAT' column\n",
    "mean = statistics.mean(group_by_invoice_filtered['Total Exclude VAT'])\n",
    "median = statistics.median(group_by_invoice_filtered['Total Exclude VAT'])\n",
    "mode = group_by_invoice_filtered['Total Exclude VAT'].mode()[0]\n",
    "std = statistics.stdev(group_by_invoice_filtered['Total Exclude VAT'])\n",
    "Sum = group_by_invoice_filtered['Total Exclude VAT'].sum()\n",
    "min_val = group_by_invoice_filtered['Total Exclude VAT'].min()\n",
    "max_val = group_by_invoice_filtered['Total Exclude VAT'].max()\n",
    "q1 = np.percentile(group_by_invoice_filtered['Total Exclude VAT'], 25)\n",
    "q3 = np.percentile(group_by_invoice_filtered['Total Exclude VAT'], 75)\n",
    "# Extract the desired values from the summary\n",
    "mean1 = stat.loc['mean']\n",
    "std1 = stat.loc['std']\n",
    "min_val1 = stat.loc['min']\n",
    "max_val1 = stat.loc['max']\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)\n",
    "print(\"Standard Deviation:\", std)\n",
    "print (\"Sum:\", Sum)\n",
    "print(\"Minimum Value:\", min_val)\n",
    "print(\"Maximum Value:\", max_val)\n",
    "print('Q1:', q1)\n",
    "print('Q3:', q3)\n",
    "\n",
    "# print(\"Mode of Total Exculde VAT\", group_by_invoice['Total Exclude VAT'].mode()[0])\n",
    "\n",
    "# Create a DataFrame with the calculated statistical measures \n",
    "summary_statistic_df = pd.DataFrame({'Mean': [mean],\n",
    "                                     'Median': [median],\n",
    "                                     'Mode': [mode],\n",
    "                                     'Standard Deviation': [std],\n",
    "                                     'Sum': [Sum],\n",
    "                                     'Minimum Value': [min_val],\n",
    "                                     'Maximum Value': [max_val]})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "# summary_statistic_df.to_excel('Summary Statistic M3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Update bins and labels for the new range concept\n",
    "bins = np.concatenate(([0], np.arange(0, 16000, 16000), np.arange(16000, 30000, 14000), np.arange(30000, 53000, 23000), np.arange(53000, 350001, 297000), [np.inf]))\n",
    "bins = np.unique(bins)  # Remove duplicate edges\n",
    "\n",
    "# Update labels\n",
    "labels = ['{} to {}' .format(i, i+15999) for i in range(0, 16000, 16000)] + ['{} to {}' .format(i, i+13999) for i in range(16000, 30000, 14000)] + ['{} to {}' .format(i, i+22999) for i in range(30000, 53000, 23000)] + ['{} to {}' .format(i, i+296999) for i in range(53000, 350000, 297000)]+ ['>=350000']\n",
    "\n",
    "def grouped_data(df_filtered):\n",
    "    df_filtered['Basket Value'] = pd.cut(df_filtered['Total Exclude VAT'], bins=bins, labels=labels)\n",
    "    grouped_data = df_filtered.groupby('Basket Value')['Total Exclude VAT'].agg(['count','mean','median'])\n",
    "\n",
    "    # Add a new column for Count x Mean\n",
    "    grouped_data['Value'] = grouped_data['count'] * grouped_data['mean']\n",
    "\n",
    "    # Update x-axis labels\n",
    "    grouped_data.index = grouped_data.index.astype(str).str.replace(',', '')\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "grouped_data = grouped_data(group_by_invoice_filtered)\n",
    "\n",
    "grouped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Calculate total value\n",
    "total_value = grouped_data['Value'].sum()\n",
    "\n",
    "# Add a new column for %Value in total\n",
    "grouped_data['%Value in total'] = grouped_data['Value'] / total_value * 100\n",
    "\n",
    "# Plot histogram for count\n",
    "fig, ax1 = plt.subplots()\n",
    "n, bins, patches = ax1.hist(df_filtered['Total Exclude VAT'], bins=bins, cumulative=False, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.set_xlabel('Basket Value')\n",
    "ax1.set_ylabel('Count (in units)')\n",
    "ax1.set_title('Basket Value Distribution - Bill')\n",
    "ax1.legend(['Count'], loc='upper left')\n",
    "ax1.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(int(x))))\n",
    "\n",
    "# Plot histogram for value\n",
    "fig, ax2 = plt.subplots()\n",
    "n2, bins2, patches2 = ax2.hist(df_filtered['Total Exclude VAT'], bins=bins, cumulative=False, alpha=0.7, color='red', edgecolor='black', weights=df_filtered['Total Exclude VAT'])\n",
    "ax2.set_xlabel('Basket Value')\n",
    "ax2.set_ylabel('Value (in VND)')\n",
    "ax2.set_title('Basket Value Distribution - Value')\n",
    "ax2.legend(['Value'], loc='upper left')\n",
    "ax2.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(int(x))))\n",
    "\n",
    "# Add percentage value labels to the top of each column\n",
    "for i in range(len(patches2)):\n",
    "    height = patches2[i].get_height()\n",
    "    percentage = height / total_value * 100\n",
    "    ax2.annotate(f'{percentage:.1f}%', xy=(patches2[i].get_x() + patches2[i].get_width() / 2, height), xytext=(0, 3), textcoords='offset points', ha='center')\n",
    "\n",
    "# Highlight columns with cumulative %Value in total up to 80%\n",
    "cumulative_percentage = 0\n",
    "for i, patch in enumerate(patches2):\n",
    "    cumulative_percentage += grouped_data['%Value in total'].iloc[i]\n",
    "    if cumulative_percentage <= 80:\n",
    "        patch.set_fc('green')\n",
    "    else:\n",
    "        patch.set_fc('red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display grouped data with additional column\n",
    "grouped_data['Count'] = grouped_data['count'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "grouped_data['Mean'] = grouped_data['mean'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "grouped_data['Median'] = grouped_data['median'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "grouped_data['Count x Mean'] = grouped_data['Value'].apply(lambda x: '{:,.0f}'.format(x))\n",
    "grouped_data = grouped_data[['Count', 'Mean', 'Median', 'Value', '%Value in total']]\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# grouped_data.to_csv('groupdataM1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Apply string slicing to create new columns 'StorID' and 'BusinessDate'\n",
    "group_by_invoice_filtered['StoreID'] = group_by_invoice_filtered['InvoiceID'].map(lambda x: x[:6])\n",
    "group_by_invoice_filtered['BusinessDate'] = group_by_invoice_filtered['InvoiceID'].map(lambda x: x[8:14])\n",
    "\n",
    "# Reorder the columns\n",
    "group_by_invoice_filtered = group_by_invoice_filtered.reindex (columns=['InvoiceID','StoreID','BusinessDate','Barcode','Sum of Qty','Total Exclude VAT','SubCategory Name'])\n",
    "\n",
    "# Show the first 5 rows\n",
    "group_by_invoice_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Group by StoreID and aggregate by 'InvoiceID', 'Total Exclude VAT', 'Sum of Qty' and 'BusinessDate'\n",
    "\n",
    "grouped_by_store_net = group_by_invoice_filtered.groupby('StoreID').agg({'InvoiceID': 'nunique','Total Exclude VAT': 'sum', 'Sum of Qty': 'sum', 'BusinessDate': 'nunique'})\n",
    "\n",
    "# Calculate the ADS, ADQ and ASI\n",
    "\n",
    "grouped_by_store_net['ADS'] = grouped_by_store_net['Total Exclude VAT'] / grouped_by_store_net['BusinessDate']\n",
    "grouped_by_store_net['ADQ'] = grouped_by_store_net['Sum of Qty'] / grouped_by_store_net['BusinessDate']\n",
    "grouped_by_store_net['ASI'] = grouped_by_store_net['Total Exclude VAT'] / grouped_by_store_net['Sum of Qty']\n",
    "grouped_by_store_net['CUS'] = grouped_by_store_net['InvoiceID'] / grouped_by_store_net['BusinessDate']\n",
    "grouped_by_store_net['BV'] = grouped_by_store_net['ADS'] / grouped_by_store_net['CUS']\n",
    "grouped_by_store_net['Avg_Items_Per_Bill'] = grouped_by_store_net['ADQ'] / grouped_by_store_net['CUS']\n",
    "\n",
    "# Reset the index to make 'StoreID' a regular column\n",
    "\n",
    "grouped_by_store_net = grouped_by_store_net.reset_index()\n",
    "\n",
    "grouped_by_store_net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column 'Basket Value' based on the column 'Total Exclude VAT'\n",
    "group_by_invoice_filtered['Basket Value'] = pd.cut(group_by_invoice_filtered['Total Exclude VAT'], bins=bins, labels=labels)\n",
    "\n",
    "# Create a new dataframe 'group_basket_store' = group_by_invoice_filtered\n",
    "group_basket_store = group_by_invoice_filtered\n",
    "\n",
    "# Apply string slicing to create new column 'StoreID'\n",
    "group_basket_store['StoreID'] = group_basket_store['InvoiceID'].map(lambda x: x[:6])\n",
    "\n",
    "# Keep only the columns 'InvoiceID', 'Sum of Qty', 'Total Exclude VAT', 'Basket Value' and 'StoreID'\n",
    "group_basket_store = group_basket_store[['InvoiceID','Sum of Qty','Total Exclude VAT','Basket Value','StoreID']].reindex(columns=['Basket Value','StoreID','InvoiceID','Sum of Qty','Total Exclude VAT'])\n",
    "\n",
    "# Group by 'Basket Value' and 'StoreID' and aggregate by 'Total Exclude VAT'\n",
    "group_basket_store = group_basket_store.groupby(['Basket Value','StoreID']).agg({'Total Exclude VAT': ['count', 'mean', 'median']})\n",
    "\n",
    "# Access columns using tuple indexing and compute 'Value' column\n",
    "group_basket_store.loc[:, ('Total Exclude VAT','Value')] = group_basket_store[('Total Exclude VAT','count')] * group_basket_store[('Total Exclude VAT','mean')]\n",
    "\n",
    "group_basket_store.reset_index(inplace=True)\n",
    "\n",
    "group_basket_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_read_cate = pd.read_excel(r'C:\\Users\\trieu.pham\\OneDrive - BTM Global Consulting\\Projects\\github\\python\\Python\\Data Analysis\\DataCate.xlsx', sheet_name='Sheet1', usecols=[0,2])\n",
    "except:\n",
    "    df_read_cate = pd.read_excel(r'C:\\Users\\Trieu Pham\\OneDrive - BTM Global Consulting\\Projects\\github\\python\\Python\\Data Analysis\\DataCate.xlsx', sheet_name='Sheet1', usecols=[0,2])\n",
    "df_read_cate['Barcode'] = df_read_cate['Barcode'].astype(str)\n",
    "df_filtered = pd.merge(df_filtered, df_read_cate, on='Barcode', how='left')\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "group_basket_cate_subcate = df_filtered\n",
    "\n",
    "# filter group_basket_cate_subcate by upper_bound and lower_bound\n",
    "upper_bound = 50000000\n",
    "lower_bound = 1000\n",
    "group_basket_cate_subcate = group_basket_cate_subcate[(group_basket_cate_subcate['Total Exclude VAT'] < upper_bound) & (group_basket_cate_subcate['Total Exclude VAT'] > lower_bound)]\n",
    "group_basket_cate_subcate['Basket Value'] = pd.cut(df_filtered['Total Exclude VAT'], bins=bins, labels=labels)\n",
    "\n",
    "# group_basket_cate_subcate.to_csv('group_basket_cate.csv')\n",
    "group_basket_cate_subcate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "queries = group_basket_cate_subcate[(group_basket_cate_subcate['Total Exclude VAT'] < 1000)]\n",
    "\n",
    "group_basket_cate_subcate['StoreID'] = group_basket_cate_subcate['InvoiceID'].map(lambda x: x[:6])\n",
    "\n",
    "group_basket_cate_subcate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the sum of 'Total Exclude VAT', grouped by 'Basket Value', 'Category Name' and 'SubCategory Name'\n",
    "total_exclude_vat_by_category = group_basket_cate_subcate.groupby(['Basket Value','Category Name','SubCategory Name']).agg({'Total Exclude VAT':'sum'}).reset_index()\n",
    "\n",
    "# total_exclude_vat_by_category.sort_values(by=['Total Exclude VAT'], ascending=True)\n",
    "\n",
    "# Get the top 5 categories based on the sum of 'Total Exclude VAT', grouped by 'Basket Value'\n",
    "top_5_categories = total_exclude_vat_by_category.groupby('Basket Value').apply(lambda x: x.nlargest(5, 'Total Exclude VAT')).reset_index(drop=True)\n",
    "\n",
    "# Get the top 10 subcategories based on the sum of 'Total Exclude VAT', grouped by 'Basket Value'\n",
    "top_10_subcategories = total_exclude_vat_by_category.groupby('Basket Value').apply(lambda x: x.nlargest(10, 'Total Exclude VAT')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "top_5_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "top_5_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "top_10_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the sum of 'Total Exclude VAT', grouped by 'Basket Value', 'Category Name' and 'StoreID'\n",
    "total_exclude_vat_by_category_store = group_basket_cate_subcate.groupby(['Basket Value','Category Name','StoreID']).agg({'Total Exclude VAT':'sum'}).reset_index()\n",
    "\n",
    "# Get the top 5 categories based on the sum of 'Total Exclude VAT', grouped by 'Basket Value' for each store\n",
    "top_5_categories_store = total_exclude_vat_by_category_store.groupby(['Basket Value','StoreID']).apply(lambda x: x.nlargest(5, 'Total Exclude VAT')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "top_5_categories_store\n",
    "# top_5_categories_store.to_csv('top_5_categories_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the sum of 'Total Exclude VAT', grouped by 'Basket Value', 'SubCategory Name' and 'StoreID'\n",
    "total_exclude_vat_by_subcategory_store = group_basket_cate_subcate.groupby(['Basket Value','SubCategory Name','StoreID']).agg({'Total Exclude VAT':'sum'}).reset_index()\n",
    "\n",
    "# Get the top 10 subcategories based on the sum of 'Total Exclude VAT', grouped by 'Basket Value' for each store\n",
    "top_10_subcategories_store = total_exclude_vat_by_subcategory_store.groupby(['Basket Value','StoreID']).apply(lambda x: x.nlargest(10, 'Total Exclude VAT')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "top_10_subcategories_store\n",
    "# top_10_subcategories_store.to_csv('top_10_subcategories_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "# StoreID and BusinessDate added to the filter dataframe\n",
    "df_filtered['InvoiceID'] = df_filtered['InvoiceID'].astype(str)\n",
    "df_filtered['StoreID'] = df_filtered['InvoiceID'].apply(lambda x: x[:6])\n",
    "df_filtered['BusinessDate'] = df_filtered['InvoiceID'].apply(lambda x: x[8:14])\n",
    "\n",
    "# Group by Basket Value and StoreID and calculate count and mean\n",
    "grouped_data_store = df_filtered.groupby(['InvoiceID', 'StoreID']).agg({'InvoiceID': 'count', 'Total Exclude VAT': 'mean'})\n",
    "grouped_data_store.rename(columns={'InvoiceID': 'count', 'Total Exclude VAT': 'mean'}, inplace=True)\n",
    "grouped_data_store.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the 'value' column as the product of 'mean' and 'count'\n",
    "grouped_data_store['Value'] = grouped_data_store['mean'] * grouped_data_store['count']\n",
    "\n",
    "# Drop rows with NaN or 0 values in 'mean' or 'Value' columns\n",
    "grouped_data_store.dropna(subset=['mean', 'Value'], inplace=True)\n",
    "grouped_data_store = grouped_data_store[(grouped_data_store['mean'] != 0) & (grouped_data_store['Value'] != 0)]\n",
    "\n",
    "# Fit RANSAC Regression model to 'Value' and 'mean' columns\n",
    "X = grouped_data_store[['Value']].values\n",
    "y = grouped_data_store['mean'].values\n",
    "\n",
    "regressor = RANSACRegressor()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Predict the mean values using the fitted model\n",
    "y_pred = regressor.predict(X)\n",
    "\n",
    "# Calculate the residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Set a threshold for identifying outliers\n",
    "threshold = 1.5 * np.median(np.abs(residuals))\n",
    "\n",
    "# Identify outliers based on residuals\n",
    "outliers = grouped_data_store[residuals > threshold]\n",
    "\n",
    "# Remove outliers from the grouped_data_store DataFrame\n",
    "grouped_data_store_clean = grouped_data_store[residuals <= threshold]\n",
    "\n",
    "# Show the cleaned grouped data columns\n",
    "print(grouped_data_store_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sort the 'grouped_data_store' DataFrame by the 'value' column in descending order\n",
    "grouped_data_store.sort_values('Value', ascending=False, inplace=True)\n",
    "\n",
    "# Calculate the cumulative sum of the 'value' column\n",
    "grouped_data_store['cumulative_sum'] = grouped_data_store['Value'].cumsum()\n",
    "\n",
    "# Calculate the cumulative distribution percentage\n",
    "grouped_data_store['cumulative_percentage'] = grouped_data_store['cumulative_sum'] / grouped_data_store['Value'].sum()\n",
    "\n",
    "# Filter rows where the cumulative percentage is less than or equal to 0.8\n",
    "filtered_data = grouped_data_store[grouped_data_store['cumulative_percentage'] >= 0.8]\n",
    "\n",
    "# Print the filtered results\n",
    "print(filtered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "R",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f2380935a852bfd6cd376048d8438f0291ac020ced12a3def74eecbc5a3998c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
